{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Settings and Hyperparameters\n",
    "# -------------------------------\n",
    "m = 100            # number of sensor points (and collocation x values)\n",
    "P = 100            # number of boundary points per sample\n",
    "Q = 100            # number of collocation points per sample (here, Q = m)\n",
    "N_train = 10000    # number of training input functions\n",
    "D_val = 0.01       # diffusion coefficient\n",
    "k_val = 1.0        # reaction coefficient\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Generate Training Input Functions u(x)\n",
    "# -------------------------------\n",
    "# (Assume a Gaussian Random Field sampler; here we use a simple placeholder.)\n",
    "# For a real GRF, one could use gstools or similar.\n",
    "def sample_grf(num_points, num_functions, length_scale=0.2, var=3.0, seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    # Here we use a simple RBF covariance to generate samples.\n",
    "    x_grid = np.linspace(0, 1, num_points)\n",
    "    X1, X2 = np.meshgrid(x_grid, x_grid)\n",
    "    cov = var * np.exp(-((X1 - X2)**2) / (2*length_scale**2))\n",
    "    # For simplicity, we generate independent normals at each sensor.\n",
    "    # (This is not a proper GRF, but serves as a placeholder.)\n",
    "    U = np.random.randn(num_points, num_functions)\n",
    "    return x_grid, U  # U shape: (m, N_train)\n",
    "\n",
    "x, U = sample_grf(m, N_train, length_scale=0.2)\n",
    "# U_data: each sample is a row vector (u(x) evaluated at m sensors)\n",
    "U_data = torch.tensor(U.T, dtype=torch.float32)  # shape: (N_train, m)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define the PI-DeepONet Model\n",
    "# -------------------------------\n",
    "class DeepONet(nn.Module):\n",
    "    def __init__(self, m, hidden_dim=50, num_layers=5, trunk_input_dim=2):\n",
    "        \"\"\"\n",
    "        m: number of sensor points (dimension of u)\n",
    "        trunk_input_dim: dimension of the trunk input (here, 2 for (x,t))\n",
    "        \"\"\"\n",
    "        super(DeepONet, self).__init__()\n",
    "        self.m = m\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Branch network: input dimension = m, output dimension = hidden_dim.\n",
    "        layers_branch = []\n",
    "        in_dim = m\n",
    "        for i in range(num_layers - 1):\n",
    "            layers_branch.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers_branch.append(nn.Tanh())\n",
    "            in_dim = hidden_dim\n",
    "        layers_branch.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.branch_net = nn.Sequential(*layers_branch)\n",
    "        \n",
    "        # Trunk network: input dimension = trunk_input_dim (here 2), output dimension = hidden_dim.\n",
    "        layers_trunk = []\n",
    "        in_dim = trunk_input_dim\n",
    "        for i in range(num_layers - 1):\n",
    "            layers_trunk.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers_trunk.append(nn.Tanh())\n",
    "            in_dim = hidden_dim\n",
    "        layers_trunk.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.trunk_net = nn.Sequential(*layers_trunk)\n",
    "        \n",
    "        # Learnable bias\n",
    "        self.bias = nn.Parameter(torch.tensor(0.0))\n",
    "        \n",
    "    def forward(self, u, xt):\n",
    "        \"\"\"\n",
    "        u: tensor of shape (B, m) --- input function samples.\n",
    "        xt: tensor of shape (B, num_query, 2) --- query points (x,t).\n",
    "        Returns: tensor of shape (B, num_query) --- network output.\n",
    "        \"\"\"\n",
    "        B, num_query, _ = xt.shape\n",
    "        branch_out = self.branch_net(u)  # shape: (B, hidden_dim)\n",
    "        \n",
    "        # Evaluate trunk net: flatten xt from (B, num_query, 2) -> (B*num_query, 2)\n",
    "        trunk_in = xt.view(-1, 2)\n",
    "        trunk_out = self.trunk_net(trunk_in)  # shape: (B*num_query, hidden_dim)\n",
    "        trunk_out = trunk_out.view(B, num_query, self.hidden_dim)  # (B, num_query, hidden_dim)\n",
    "        \n",
    "        # Dot product between branch and trunk outputs:\n",
    "        # Expand branch_out: (B, 1, hidden_dim) then multiply with trunk_out and sum along hidden_dim.\n",
    "        s = torch.sum(branch_out.unsqueeze(1) * trunk_out, dim=2) + self.bias  # shape: (B, num_query)\n",
    "        return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch     0 | Loss: 1.008437 | LR: 1.000000e-03\n",
      "Epoch   100 | Loss: 0.984773 | LR: 1.000000e-03\n",
      "Epoch   200 | Loss: 0.984414 | LR: 1.000000e-03\n",
      "Epoch   300 | Loss: 0.983664 | LR: 1.000000e-03\n",
      "Epoch   400 | Loss: 0.982105 | LR: 1.000000e-03\n",
      "Epoch   500 | Loss: 0.976604 | LR: 1.000000e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 144\u001b[0m\n\u001b[0;32m    142\u001b[0m     loss_val\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    143\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 144\u001b[0m     loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m loss_epoch \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m    147\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss_epoch)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model and send to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "# -------------------------------\n",
    "# 3. Helper Functions for Sampling Points\n",
    "# -------------------------------\n",
    "def sample_boundary_points(B, P):\n",
    "    \"\"\"\n",
    "    For each sample (B), sample P points on the boundary of [0,1]x[0,1]\n",
    "    (enforcing zero initial and spatial-boundary conditions).\n",
    "    We sample from three parts:\n",
    "      - initial condition: t = 0, x ~ U(0,1)\n",
    "      - left boundary: x = 0, t ~ U(0,1)\n",
    "      - right boundary: x = 1, t ~ U(0,1)\n",
    "    \"\"\"\n",
    "    P1 = P // 3\n",
    "    P2 = P // 3\n",
    "    P3 = P - P1 - P2  # to account for remainders\n",
    "    \n",
    "    # Initial: t=0\n",
    "    x_init = torch.rand(B, P1, 1)\n",
    "    t_init = torch.zeros(B, P1, 1)\n",
    "    bc_init = torch.cat([x_init, t_init], dim=2)  # (B, P1, 2)\n",
    "    \n",
    "    # Left boundary: x=0\n",
    "    x_left = torch.zeros(B, P2, 1)\n",
    "    t_left = torch.rand(B, P2, 1)\n",
    "    bc_left = torch.cat([x_left, t_left], dim=2)\n",
    "    \n",
    "    # Right boundary: x=1\n",
    "    x_right = torch.ones(B, P3, 1)\n",
    "    t_right = torch.rand(B, P3, 1)\n",
    "    bc_right = torch.cat([x_right, t_right], dim=2)\n",
    "    \n",
    "    boundary_points = torch.cat([bc_init, bc_left, bc_right], dim=1)  # shape: (B, P, 2)\n",
    "    return boundary_points\n",
    "\n",
    "def sample_collocation_points(B, sensor_x):\n",
    "    \"\"\"\n",
    "    For each sample, we use the sensor grid for the spatial coordinate and sample a time in [0,1].\n",
    "    sensor_x: tensor of shape (m, 1) --- the fixed sensor locations.\n",
    "    Returns: collocation points of shape (B, m, 2) with\n",
    "             first column = sensor_x (repeated), second column = random t.\n",
    "    \"\"\"\n",
    "    m = sensor_x.shape[0]\n",
    "    collocation_x = sensor_x.unsqueeze(0).repeat(B, 1, 1)  # (B, m, 1)\n",
    "    collocation_t = torch.rand(B, m, 1, device=device)  # (B, m, 1) sampled uniformly in [0,1]\n",
    "    collocation_points = torch.cat([collocation_x, collocation_t], dim=2)  # (B, m, 2)\n",
    "    return collocation_points\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Define Loss Functions\n",
    "# -------------------------------\n",
    "def operator_loss(model, u_batch, boundary_points):\n",
    "    \"\"\"\n",
    "    Enforces zero initial and boundary conditions:\n",
    "      GÎ¸(u)(x,t) should be zero on the boundary.\n",
    "    boundary_points: tensor of shape (B, P, 2)\n",
    "    \"\"\"\n",
    "    s_boundary = model(u_batch, boundary_points)  # shape: (B, P)\n",
    "    loss_op = torch.mean(s_boundary**2)\n",
    "    return loss_op\n",
    "\n",
    "def physics_loss(model, u_batch, sensor_x):\n",
    "    \"\"\"\n",
    "    Enforces the PDE residual at collocation points.\n",
    "    For each sample, we set spatial collocation points as sensor_x (of shape (m,1))\n",
    "    and sample a time coordinate.\n",
    "    Computes R = s_t - D * s_xx - k * s^2, and penalizes (R - u(x))^2.\n",
    "    \"\"\"\n",
    "    B = u_batch.size(0)\n",
    "    # Generate collocation points: (B, m, 2)\n",
    "    collocation_points = sample_collocation_points(B, sensor_x)\n",
    "    # Make sure collocation_points requires grad (to compute derivatives)\n",
    "    collocation_points = collocation_points.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Evaluate network output s = GÎ¸(u)(x,t) at collocation points.\n",
    "    s = model(u_batch, collocation_points)  # shape: (B, m)\n",
    "    \n",
    "    # --- Compute time derivative s_t ---\n",
    "    # We sum s to get a scalar and differentiate wrt collocation_points.\n",
    "    s_sum = s.sum()\n",
    "    grad_all = torch.autograd.grad(s_sum, collocation_points, create_graph=True)[0]\n",
    "    # grad_all has shape (B, m, 2); the second coordinate (index 1) is the derivative wrt t.\n",
    "    s_t = grad_all[..., 1]  # (B, m)\n",
    "    \n",
    "    # --- Compute second spatial derivative s_xx ---\n",
    "    # First derivative wrt x (index 0)\n",
    "    s_x = grad_all[..., 0]  # (B, m)\n",
    "    s_x_sum = s_x.sum()\n",
    "    grad_sx = torch.autograd.grad(s_x_sum, collocation_points, create_graph=True)[0]\n",
    "    s_xx = grad_sx[..., 0]  # (B, m)\n",
    "    \n",
    "    # PDE residual: R = s_t - D * s_xx - k * s^2\n",
    "    R = s_t - D_val * s_xx - k_val * s**2  # (B, m)\n",
    "    \n",
    "    # The forcing term is u(x), which for each sample is given in u_batch.\n",
    "    # (Assuming the sensor ordering in u_batch matches sensor_x.)\n",
    "    loss_phys = torch.mean((R - u_batch)**2)\n",
    "    return loss_phys\n",
    "\n",
    "def total_loss(model, u_batch, sensor_x, boundary_points):\n",
    "    L_op = operator_loss(model, u_batch, boundary_points)\n",
    "    L_phys = physics_loss(model, u_batch, sensor_x)\n",
    "    return L_op + L_phys\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Prepare DataLoader and Training Setup\n",
    "# -------------------------------\n",
    "batch_size = 10000  # choose a batch size (you can adjust this)\n",
    "train_dataset = TensorDataset(U_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# sensor_x: fixed spatial sensor locations (m, 1)\n",
    "sensor_x = torch.tensor(x, dtype=torch.float32).view(m, 1)\n",
    "\n",
    "\n",
    "model = DeepONet(m=m, hidden_dim=50, num_layers=5, trunk_input_dim=2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.9**(epoch//10000))\n",
    "# Optional: you can also add a learning rate scheduler if desired.\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Training Loop\n",
    "# -------------------------------\n",
    "epochs = 120000\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_epoch = 0.0\n",
    "    for (u_batch,) in train_loader:\n",
    "        B = u_batch.size(0)\n",
    "        u_batch = u_batch.to(device)  # shape: (B, m)\n",
    "        \n",
    "        # Sample boundary points for this batch: shape (B, P, 2)\n",
    "        boundary_points = sample_boundary_points(B, P).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_val = total_loss(model, u_batch, sensor_x.to(device), boundary_points)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss_val.item()\n",
    "    \n",
    "    loss_epoch /= len(train_loader)\n",
    "    train_losses.append(loss_epoch)\n",
    "    if epoch % 100 == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch:5d} | Loss: {loss_epoch:.6f} | LR: {current_lr:.6e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
